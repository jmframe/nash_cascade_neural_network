{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45cb35ce-803e-43be-b263-4a1a0f3bb6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nash Cascade Neural Network\n",
    "# A hydrologically intuitive deep learning network\n",
    "\n",
    "# Set up a solution to a network of buckets where the number of buckets in each layer\n",
    "# flows out to the buckets in the next layer\n",
    "# The parameter on each bucket is the size and height of each spigot.\n",
    "\n",
    "# Need a function that solves this individually at a single buckets\n",
    "# Then a function that loops through and moves the water to the downstream buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bab940-cde5-4ff0-8897-75fdf2ebec52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from ncn_fcnn import NashCascadeNetwork as ncn\n",
    "from ncn_fcnn import train_model as train_ncnn\n",
    "import matplotlib.font_manager as font_manager\n",
    "# Precipitation standard variable name used in the ncnn model interface\n",
    "PRECIP_SVN = \"atmosphere_water__liquid_equivalent_precipitation_rate\"\n",
    "PRECIP_SVN_SEQ = \"atmosphere_water__liquid_equivalent_precipitation_rate_seq\"\n",
    "PRECIP_RECORD = \"atmosphere_water__liquid_equivalent_precipitation_rate_record\"\n",
    "DO_PLOT = True\n",
    "N_TIMESTEPS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46bcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_precip_input_list = []\n",
    "count = 0\n",
    "unit_precip = 6.0\n",
    "for i in range(N_TIMESTEPS):\n",
    "\n",
    "    ###########################################################################\n",
    "    if count == 0:\n",
    "        network_precip_input_list.append(unit_precip)\n",
    "    elif count > 45:\n",
    "        network_precip_input_list.append(unit_precip)\n",
    "    else:\n",
    "        network_precip_input_list.append(np.random.random()*unit_precip/10)\n",
    "    if count == 50:\n",
    "        count = 0\n",
    "    count+=1\n",
    "    ###########################################################################\n",
    "network_precip_tensor = torch.tensor(network_precip_input_list, requires_grad=False)\n",
    "total_mass_precip_in = torch.sum(network_precip_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92cb4cbf-61b3-4566-a9e0-37d15e846fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "-----------\n",
      "-------------\n",
      "\n",
      "INITIAL THETA VALUES\n",
      "tensor([0.2349, 0.2402, 0.2022, 0.2169, 0.2294], requires_grad=True)\n",
      "--------------\n",
      "-----------\n",
      "-------------\n",
      "\n",
      "Initial Mass in network at start: 20.0\n",
      "Initial Mass in network: 20.0\n",
      "Final Mass in network: 27.6\n",
      "Total Mass out of network 253.1\n",
      "Total precipitation into network 260.8\n",
      "Mass balance for network is 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2349, 0.2402, 0.2022, 0.2169, 0.2294])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 0\n",
    "bucket_net = ncn(cfg_file=\"./config_0.json\")\n",
    "bucket_net.initialize()\n",
    "bucket_net.unit_precip = unit_precip\n",
    "bucket_net.summarize_network()\n",
    "inital_mass_in_network = torch.sum(torch.tensor([tensor.item() for tensor in bucket_net.sum_H_per_layer]))\n",
    "print(f\"Initial Mass in network at start: {inital_mass_in_network:.1f}\")\n",
    "network_outflow_list_0 = []\n",
    "for i in range(N_TIMESTEPS):\n",
    "\n",
    "    ###########################################################################\n",
    "    ###########################################################################\n",
    "    bucket_net.set_value(PRECIP_SVN, torch.tensor(network_precip_input_list[i], requires_grad=False))\n",
    "    bucket_net.update()\n",
    "    network_outflow_list_0.append(bucket_net.network_outflow.item())\n",
    "    bucket_net.summarize_network()\n",
    "    ###########################################################################\n",
    "    ###########################################################################\n",
    "\n",
    "network_outflow_tensor_0 = torch.tensor(network_outflow_list_0, requires_grad=True)\n",
    "bucket_net.report_out_mass_balance()\n",
    "bucket_net.theta.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694044a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(thislinewillstopthenotebookfromgoinganyfurther)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744fc71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "-----------\n",
      "-------------\n",
      "\n",
      "INITIAL THETA VALUES\n",
      "tensor([0.9957, 0.9947, 0.9961, 0.9927, 0.9942], requires_grad=True)\n",
      "--------------\n",
      "-----------\n",
      "-------------\n",
      "\n",
      "Initialized\n",
      "Initial Mass in network at start: 20.0\n",
      "Initial Mass in network: 20.0\n",
      "Final Mass in network: 53.3\n",
      "Total Mass out of network 227.4\n",
      "Total precipitation into network 260.8\n",
      "Mass balance for network is 0.000\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "bucket_nn = ncn(cfg_file=\"./config_1_fcnn.json\")\n",
    "bucket_nn.initialize()\n",
    "bucket_nn.unit_precip = unit_precip\n",
    "print(\"Initialized\")\n",
    "inital_mass_in_network = torch.sum(torch.stack(bucket_nn.sum_H_per_layer)).item()\n",
    "print(f\"Initial Mass in network at start: {inital_mass_in_network:.1f}\")\n",
    "network_outflow_list_1a = []\n",
    "\n",
    "for i in range(N_TIMESTEPS):\n",
    "    # Set the current precipitation value\n",
    "    bucket_nn.set_value(PRECIP_SVN, torch.tensor(network_precip_input_list[i], requires_grad=True))\n",
    "\n",
    "    # Update the network (this should internally prepare and use the FCNN inputs)\n",
    "    bucket_nn.update()\n",
    "    network_outflow_list_1a.append(bucket_nn.network_outflow.item())\n",
    "    bucket_nn.summarize_network()\n",
    "    ###########################################################################\n",
    "    ###########################################################################\n",
    "\n",
    "###########################################################################\n",
    "bucket_nn.report_out_mass_balance()\n",
    "\n",
    "origional_bucket_theta = copy.deepcopy(bucket_nn.theta.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecf6571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x333.333 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startplt = 230\n",
    "endplt = 280\n",
    "bigfontsize = 12\n",
    "smallfontsize = 10\n",
    "# Set figure size to 7 inches wide\n",
    "figure_width = 5  # inches\n",
    "aspect_ratio = 3 / 2  # Adjust as needed for your plot\n",
    "figure_height = figure_width / aspect_ratio\n",
    "\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Set color\n",
    "light_blue_color = \"#3D68CA\"\n",
    "line_and_text_color = \"#0D3F6E\"\n",
    "\n",
    "# Plot each series with specified color\n",
    "plt.plot(network_precip_input_list[startplt:endplt], c=light_blue_color, lw=3, label=\"Precipitation input\")\n",
    "plt.plot(network_outflow_list_0[startplt:endplt], c=\"k\", lw=3, label=\"Target hydrograph \")\n",
    "plt.plot(network_outflow_list_1a[startplt:endplt], \"--\", lw=2, c=line_and_text_color, label=\"Pre-trained network\")\n",
    "\n",
    "network_precip_tensor = torch.tensor(network_precip_input_list)\n",
    "max_value = torch.max(network_precip_tensor[startplt:endplt]).item()\n",
    "\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Unit hydrograph\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "plt.xlabel(\"Time\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "\n",
    "# Modify legend to have a transparent background\n",
    "plt.legend(fontsize=smallfontsize, edgecolor=line_and_text_color, framealpha=0.5)  # Adjust framealpha as needed\n",
    "\n",
    "#    plt.title(\"Flow out from network and precip\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "\n",
    "# Save the figure with transparent background and at 300 DPI\n",
    "plt.show()\n",
    "#plt.savefig(\"ncn_plot.png\", transparent=True, dpi=300)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8bce2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(thislinewillstopthenotebookfromrunningthecellsbelow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217de549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL MODEL theta: tensor([0.4921, 0.3090, 0.4843, 0.3580, 0.6444], grad_fn=<SigmoidBackward0>)\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "0.0894:loss  ----- Training EPOCH 0 --- theta: tensor([0.4921, 0.3090, 0.4843, 0.3580, 0.6444], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.009225438348948956\n",
      "Adjusting learning rate of group 0 to 9.6000e-03.\n",
      "0.0625:loss  ----- Training EPOCH 1 --- theta: tensor([0.5102, 0.2832, 0.4993, 0.3391, 0.6462], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.012203996069729328\n",
      "Adjusting learning rate of group 0 to 9.2160e-03.\n",
      "0.0413:loss  ----- Training EPOCH 2 --- theta: tensor([0.5286, 0.2596, 0.5138, 0.3218, 0.6471], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.015432511456310749\n",
      "Adjusting learning rate of group 0 to 8.8474e-03.\n",
      "0.0277:loss  ----- Training EPOCH 3 --- theta: tensor([0.5460, 0.2385, 0.5264, 0.3064, 0.6472], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.01843203790485859\n",
      "Adjusting learning rate of group 0 to 8.4935e-03.\n",
      "0.0219:loss  ----- Training EPOCH 4 --- theta: tensor([0.5608, 0.2204, 0.5361, 0.2928, 0.6458], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.020251912996172905\n",
      "Adjusting learning rate of group 0 to 8.1537e-03.\n",
      "0.0217:loss  ----- Training EPOCH 5 --- theta: tensor([0.5713, 0.2062, 0.5431, 0.2815, 0.6428], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.019861986860632896\n",
      "Adjusting learning rate of group 0 to 7.8276e-03.\n",
      "0.0234:loss  ----- Training EPOCH 6 --- theta: tensor([0.5770, 0.1967, 0.5478, 0.2730, 0.6384], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.017657266929745674\n",
      "Adjusting learning rate of group 0 to 7.5145e-03.\n",
      "0.0242:loss  ----- Training EPOCH 7 --- theta: tensor([0.5785, 0.1917, 0.5506, 0.2682, 0.6327], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.01469151210039854\n",
      "Adjusting learning rate of group 0 to 7.2139e-03.\n",
      "0.0233:loss  ----- Training EPOCH 8 --- theta: tensor([0.5768, 0.1904, 0.5519, 0.2670, 0.6260], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.01169105339795351\n",
      "Adjusting learning rate of group 0 to 6.9253e-03.\n",
      "0.0211:loss  ----- Training EPOCH 9 --- theta: tensor([0.5729, 0.1919, 0.5520, 0.2687, 0.6186], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.009054353460669518\n",
      "Adjusting learning rate of group 0 to 6.6483e-03.\n",
      "0.0186:loss  ----- Training EPOCH 10 --- theta: tensor([0.5675, 0.1953, 0.5513, 0.2727, 0.6106], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.006913137622177601\n",
      "Adjusting learning rate of group 0 to 6.3824e-03.\n",
      "0.0168:loss  ----- Training EPOCH 11 --- theta: tensor([0.5614, 0.1999, 0.5500, 0.2779, 0.6025], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.005258936434984207\n",
      "Adjusting learning rate of group 0 to 6.1271e-03.\n",
      "0.0159:loss  ----- Training EPOCH 12 --- theta: tensor([0.5552, 0.2051, 0.5485, 0.2834, 0.5948], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.00401628902181983\n",
      "Adjusting learning rate of group 0 to 5.8820e-03.\n",
      "0.0159:loss  ----- Training EPOCH 13 --- theta: tensor([0.5495, 0.2099, 0.5472, 0.2880, 0.5880], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0030805631540715694\n",
      "Adjusting learning rate of group 0 to 5.6467e-03.\n",
      "0.0163:loss  ----- Training EPOCH 14 --- theta: tensor([0.5445, 0.2136, 0.5463, 0.2907, 0.5823], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.002365643624216318\n",
      "Adjusting learning rate of group 0 to 5.4209e-03.\n",
      "0.0166:loss  ----- Training EPOCH 15 --- theta: tensor([0.5404, 0.2157, 0.5460, 0.2909, 0.5779], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0018052969826385379\n",
      "Adjusting learning rate of group 0 to 5.2040e-03.\n",
      "0.0164:loss  ----- Training EPOCH 16 --- theta: tensor([0.5372, 0.2162, 0.5465, 0.2887, 0.5748], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0013687643222510815\n",
      "Adjusting learning rate of group 0 to 4.9959e-03.\n",
      "0.0157:loss  ----- Training EPOCH 17 --- theta: tensor([0.5348, 0.2153, 0.5476, 0.2847, 0.5725], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0010402690386399627\n",
      "Adjusting learning rate of group 0 to 4.7960e-03.\n",
      "0.0148:loss  ----- Training EPOCH 18 --- theta: tensor([0.5328, 0.2135, 0.5491, 0.2792, 0.5709], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0008079583058133721\n",
      "Adjusting learning rate of group 0 to 4.6042e-03.\n",
      "0.0139:loss  ----- Training EPOCH 19 --- theta: tensor([0.5311, 0.2111, 0.5509, 0.2730, 0.5696], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0006596739985980093\n",
      "Adjusting learning rate of group 0 to 4.4200e-03.\n",
      "0.0132:loss  ----- Training EPOCH 20 --- theta: tensor([0.5294, 0.2087, 0.5529, 0.2666, 0.5684], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0005827201530337334\n",
      "Adjusting learning rate of group 0 to 4.2432e-03.\n",
      "0.0128:loss  ----- Training EPOCH 21 --- theta: tensor([0.5275, 0.2064, 0.5549, 0.2604, 0.5672], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.000562730710953474\n",
      "Adjusting learning rate of group 0 to 4.0735e-03.\n",
      "0.0126:loss  ----- Training EPOCH 22 --- theta: tensor([0.5253, 0.2045, 0.5567, 0.2547, 0.5659], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0005871806642971933\n",
      "Adjusting learning rate of group 0 to 3.9106e-03.\n",
      "0.0127:loss  ----- Training EPOCH 23 --- theta: tensor([0.5227, 0.2033, 0.5583, 0.2500, 0.5644], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.000634996744338423\n",
      "Adjusting learning rate of group 0 to 3.7541e-03.\n",
      "0.0128:loss  ----- Training EPOCH 24 --- theta: tensor([0.5197, 0.2026, 0.5597, 0.2463, 0.5628], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0006922182510606945\n",
      "Adjusting learning rate of group 0 to 3.6040e-03.\n",
      "0.0128:loss  ----- Training EPOCH 25 --- theta: tensor([0.5163, 0.2026, 0.5608, 0.2437, 0.5609], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.000746163830626756\n",
      "Adjusting learning rate of group 0 to 3.4598e-03.\n",
      "0.0127:loss  ----- Training EPOCH 26 --- theta: tensor([0.5126, 0.2031, 0.5615, 0.2422, 0.5590], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0007875505252741277\n",
      "Adjusting learning rate of group 0 to 3.3214e-03.\n",
      "0.0124:loss  ----- Training EPOCH 27 --- theta: tensor([0.5087, 0.2042, 0.5619, 0.2417, 0.5570], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0008108362089842558\n",
      "Adjusting learning rate of group 0 to 3.1886e-03.\n",
      "0.0121:loss  ----- Training EPOCH 28 --- theta: tensor([0.5047, 0.2056, 0.5621, 0.2419, 0.5549], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0008136032847687602\n",
      "Adjusting learning rate of group 0 to 3.0610e-03.\n",
      "0.0117:loss  ----- Training EPOCH 29 --- theta: tensor([0.5006, 0.2073, 0.5621, 0.2427, 0.5529], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.000801075657363981\n",
      "Adjusting learning rate of group 0 to 2.9386e-03.\n",
      "0.0114:loss  ----- Training EPOCH 30 --- theta: tensor([0.4967, 0.2092, 0.5620, 0.2438, 0.5511], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0007721237489022315\n",
      "Adjusting learning rate of group 0 to 2.8210e-03.\n",
      "0.0111:loss  ----- Training EPOCH 31 --- theta: tensor([0.4928, 0.2110, 0.5618, 0.2450, 0.5493], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0007297754054889083\n",
      "Adjusting learning rate of group 0 to 2.7082e-03.\n",
      "0.0109:loss  ----- Training EPOCH 32 --- theta: tensor([0.4892, 0.2128, 0.5616, 0.2462, 0.5477], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0006765903090126812\n",
      "Adjusting learning rate of group 0 to 2.5999e-03.\n",
      "0.0108:loss  ----- Training EPOCH 33 --- theta: tensor([0.4858, 0.2144, 0.5614, 0.2472, 0.5462], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0006153788999654353\n",
      "Adjusting learning rate of group 0 to 2.4959e-03.\n",
      "0.0107:loss  ----- Training EPOCH 34 --- theta: tensor([0.4826, 0.2158, 0.5612, 0.2478, 0.5450], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0005486887530423701\n",
      "Adjusting learning rate of group 0 to 2.3960e-03.\n",
      "0.0106:loss  ----- Training EPOCH 35 --- theta: tensor([0.4797, 0.2169, 0.5611, 0.2481, 0.5440], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.00047873888979665935\n",
      "Adjusting learning rate of group 0 to 2.3002e-03.\n",
      "0.0105:loss  ----- Training EPOCH 36 --- theta: tensor([0.4770, 0.2178, 0.5611, 0.2480, 0.5431], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.0004075314209330827\n",
      "Adjusting learning rate of group 0 to 2.2082e-03.\n",
      "0.0104:loss  ----- Training EPOCH 37 --- theta: tensor([0.4745, 0.2184, 0.5612, 0.2475, 0.5424], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.00033668175456114113\n",
      "Adjusting learning rate of group 0 to 2.1199e-03.\n",
      "0.0103:loss  ----- Training EPOCH 38 --- theta: tensor([0.4722, 0.2188, 0.5613, 0.2467, 0.5418], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.00026754592545330524\n",
      "Adjusting learning rate of group 0 to 2.0351e-03.\n",
      "0.0101:loss  ----- Training EPOCH 39 --- theta: tensor([0.4701, 0.2190, 0.5615, 0.2457, 0.5413], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.00020082293485756963\n",
      "Adjusting learning rate of group 0 to 1.9537e-03.\n",
      "0.0100:loss  ----- Training EPOCH 40 --- theta: tensor([0.4681, 0.2190, 0.5617, 0.2445, 0.5409], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -0.00013706967001780868\n",
      "Adjusting learning rate of group 0 to 1.8755e-03.\n",
      "0.0099:loss  ----- Training EPOCH 41 --- theta: tensor([0.4663, 0.2190, 0.5620, 0.2432, 0.5406], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -7.64041324146092e-05\n",
      "Adjusting learning rate of group 0 to 1.8005e-03.\n",
      "0.0098:loss  ----- Training EPOCH 42 --- theta: tensor([0.4645, 0.2189, 0.5622, 0.2419, 0.5403], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: -1.886081554403063e-05\n",
      "Adjusting learning rate of group 0 to 1.7285e-03.\n",
      "0.0097:loss  ----- Training EPOCH 43 --- theta: tensor([0.4628, 0.2188, 0.5624, 0.2406, 0.5400], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 3.579669646569528e-05\n",
      "Adjusting learning rate of group 0 to 1.6593e-03.\n",
      "0.0096:loss  ----- Training EPOCH 44 --- theta: tensor([0.4611, 0.2187, 0.5626, 0.2395, 0.5398], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 8.777514449320734e-05\n",
      "Adjusting learning rate of group 0 to 1.5930e-03.\n",
      "0.0095:loss  ----- Training EPOCH 45 --- theta: tensor([0.4595, 0.2186, 0.5628, 0.2384, 0.5396], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.00013738370034843683\n",
      "Adjusting learning rate of group 0 to 1.5292e-03.\n",
      "0.0094:loss  ----- Training EPOCH 46 --- theta: tensor([0.4579, 0.2186, 0.5629, 0.2375, 0.5394], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.00018480466678738594\n",
      "Adjusting learning rate of group 0 to 1.4681e-03.\n",
      "0.0094:loss  ----- Training EPOCH 47 --- theta: tensor([0.4563, 0.2186, 0.5629, 0.2367, 0.5392], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.00023011084704194218\n",
      "Adjusting learning rate of group 0 to 1.4094e-03.\n",
      "0.0093:loss  ----- Training EPOCH 48 --- theta: tensor([0.4548, 0.2187, 0.5629, 0.2361, 0.5390], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0002733839792199433\n",
      "Adjusting learning rate of group 0 to 1.3530e-03.\n",
      "0.0092:loss  ----- Training EPOCH 49 --- theta: tensor([0.4532, 0.2189, 0.5629, 0.2357, 0.5387], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.00031450740061700344\n",
      "Adjusting learning rate of group 0 to 1.2989e-03.\n",
      "0.0092:loss  ----- Training EPOCH 50 --- theta: tensor([0.4517, 0.2190, 0.5628, 0.2353, 0.5385], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0003532792325131595\n",
      "Adjusting learning rate of group 0 to 1.2469e-03.\n",
      "0.0091:loss  ----- Training EPOCH 51 --- theta: tensor([0.4502, 0.2193, 0.5628, 0.2351, 0.5383], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0003893411485478282\n",
      "Adjusting learning rate of group 0 to 1.1970e-03.\n",
      "0.0090:loss  ----- Training EPOCH 52 --- theta: tensor([0.4488, 0.2195, 0.5626, 0.2350, 0.5381], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0004241235146764666\n",
      "Adjusting learning rate of group 0 to 1.1491e-03.\n",
      "0.0089:loss  ----- Training EPOCH 53 --- theta: tensor([0.4474, 0.2198, 0.5625, 0.2349, 0.5379], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0004564392729662359\n",
      "Adjusting learning rate of group 0 to 1.1032e-03.\n",
      "0.0089:loss  ----- Training EPOCH 54 --- theta: tensor([0.4460, 0.2200, 0.5624, 0.2349, 0.5377], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0004861719789914787\n",
      "Adjusting learning rate of group 0 to 1.0591e-03.\n",
      "0.0088:loss  ----- Training EPOCH 55 --- theta: tensor([0.4447, 0.2203, 0.5622, 0.2350, 0.5374], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0005132402875460684\n",
      "Adjusting learning rate of group 0 to 1.0167e-03.\n",
      "0.0087:loss  ----- Training EPOCH 56 --- theta: tensor([0.4435, 0.2206, 0.5621, 0.2350, 0.5372], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0005376095650717616\n",
      "Adjusting learning rate of group 0 to 9.7602e-04.\n",
      "0.0087:loss  ----- Training EPOCH 57 --- theta: tensor([0.4423, 0.2209, 0.5619, 0.2351, 0.5370], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0005593339446932077\n",
      "Adjusting learning rate of group 0 to 9.3698e-04.\n",
      "0.0086:loss  ----- Training EPOCH 58 --- theta: tensor([0.4411, 0.2211, 0.5618, 0.2351, 0.5368], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0005784443928860128\n",
      "Adjusting learning rate of group 0 to 8.9950e-04.\n",
      "0.0086:loss  ----- Training EPOCH 59 --- theta: tensor([0.4401, 0.2213, 0.5616, 0.2352, 0.5367], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0005950608756393194\n",
      "Adjusting learning rate of group 0 to 8.6352e-04.\n",
      "0.0085:loss  ----- Training EPOCH 60 --- theta: tensor([0.4390, 0.2216, 0.5615, 0.2352, 0.5365], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006092978292144835\n",
      "Adjusting learning rate of group 0 to 8.2898e-04.\n",
      "0.0085:loss  ----- Training EPOCH 61 --- theta: tensor([0.4380, 0.2218, 0.5614, 0.2352, 0.5363], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006213599699549377\n",
      "Adjusting learning rate of group 0 to 7.9582e-04.\n",
      "0.0084:loss  ----- Training EPOCH 62 --- theta: tensor([0.4371, 0.2219, 0.5613, 0.2352, 0.5362], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006313833873718977\n",
      "Adjusting learning rate of group 0 to 7.6399e-04.\n",
      "0.0084:loss  ----- Training EPOCH 63 --- theta: tensor([0.4362, 0.2221, 0.5612, 0.2351, 0.5361], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006395782111212611\n",
      "Adjusting learning rate of group 0 to 7.3343e-04.\n",
      "0.0083:loss  ----- Training EPOCH 64 --- theta: tensor([0.4354, 0.2222, 0.5611, 0.2351, 0.5359], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006461279117502272\n",
      "Adjusting learning rate of group 0 to 7.0409e-04.\n",
      "0.0083:loss  ----- Training EPOCH 65 --- theta: tensor([0.4346, 0.2223, 0.5610, 0.2350, 0.5358], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006512224790640175\n",
      "Adjusting learning rate of group 0 to 6.7593e-04.\n",
      "0.0083:loss  ----- Training EPOCH 66 --- theta: tensor([0.4339, 0.2224, 0.5609, 0.2349, 0.5357], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006550588877871633\n",
      "Adjusting learning rate of group 0 to 6.4889e-04.\n",
      "0.0082:loss  ----- Training EPOCH 67 --- theta: tensor([0.4332, 0.2225, 0.5608, 0.2348, 0.5356], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006578161264769733\n",
      "Adjusting learning rate of group 0 to 6.2294e-04.\n",
      "0.0082:loss  ----- Training EPOCH 68 --- theta: tensor([0.4325, 0.2226, 0.5608, 0.2346, 0.5355], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006596589810214937\n",
      "Adjusting learning rate of group 0 to 5.9802e-04.\n",
      "0.0082:loss  ----- Training EPOCH 69 --- theta: tensor([0.4319, 0.2227, 0.5607, 0.2345, 0.5354], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006607596296817064\n",
      "Adjusting learning rate of group 0 to 5.7410e-04.\n",
      "0.0081:loss  ----- Training EPOCH 70 --- theta: tensor([0.4313, 0.2227, 0.5607, 0.2343, 0.5353], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006612683646380901\n",
      "Adjusting learning rate of group 0 to 5.5113e-04.\n",
      "0.0081:loss  ----- Training EPOCH 71 --- theta: tensor([0.4307, 0.2228, 0.5606, 0.2342, 0.5353], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006612971192225814\n",
      "Adjusting learning rate of group 0 to 5.2909e-04.\n",
      "0.0081:loss  ----- Training EPOCH 72 --- theta: tensor([0.4302, 0.2228, 0.5606, 0.2340, 0.5352], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006609802367165685\n",
      "Adjusting learning rate of group 0 to 5.0793e-04.\n",
      "0.0080:loss  ----- Training EPOCH 73 --- theta: tensor([0.4297, 0.2228, 0.5605, 0.2339, 0.5351], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006603962974622846\n",
      "Adjusting learning rate of group 0 to 4.8761e-04.\n",
      "0.0080:loss  ----- Training EPOCH 74 --- theta: tensor([0.4292, 0.2229, 0.5605, 0.2337, 0.5351], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006596160237677395\n",
      "Adjusting learning rate of group 0 to 4.6810e-04.\n",
      "0.0080:loss  ----- Training EPOCH 75 --- theta: tensor([0.4287, 0.2229, 0.5605, 0.2336, 0.5350], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006587618263438344\n",
      "Adjusting learning rate of group 0 to 4.4938e-04.\n",
      "0.0080:loss  ----- Training EPOCH 76 --- theta: tensor([0.4283, 0.2229, 0.5604, 0.2335, 0.5350], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000657860073260963\n",
      "Adjusting learning rate of group 0 to 4.3140e-04.\n",
      "0.0079:loss  ----- Training EPOCH 77 --- theta: tensor([0.4278, 0.2230, 0.5604, 0.2333, 0.5349], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006569499964825809\n",
      "Adjusting learning rate of group 0 to 4.1415e-04.\n",
      "0.0079:loss  ----- Training EPOCH 78 --- theta: tensor([0.4274, 0.2230, 0.5603, 0.2332, 0.5349], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006561066256836057\n",
      "Adjusting learning rate of group 0 to 3.9758e-04.\n",
      "0.0079:loss  ----- Training EPOCH 79 --- theta: tensor([0.4270, 0.2230, 0.5603, 0.2331, 0.5348], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000655330833978951\n",
      "Adjusting learning rate of group 0 to 3.8168e-04.\n",
      "0.0079:loss  ----- Training EPOCH 80 --- theta: tensor([0.4266, 0.2231, 0.5602, 0.2330, 0.5348], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006546180229634047\n",
      "Adjusting learning rate of group 0 to 3.6641e-04.\n",
      "0.0079:loss  ----- Training EPOCH 81 --- theta: tensor([0.4263, 0.2231, 0.5602, 0.2329, 0.5348], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006540327449329197\n",
      "Adjusting learning rate of group 0 to 3.5176e-04.\n",
      "0.0079:loss  ----- Training EPOCH 82 --- theta: tensor([0.4259, 0.2231, 0.5602, 0.2328, 0.5347], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006535404245369136\n",
      "Adjusting learning rate of group 0 to 3.3769e-04.\n",
      "0.0078:loss  ----- Training EPOCH 83 --- theta: tensor([0.4256, 0.2231, 0.5601, 0.2327, 0.5347], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006531905964948237\n",
      "Adjusting learning rate of group 0 to 3.2418e-04.\n",
      "0.0078:loss  ----- Training EPOCH 84 --- theta: tensor([0.4252, 0.2232, 0.5601, 0.2326, 0.5347], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000652952294331044\n",
      "Adjusting learning rate of group 0 to 3.1121e-04.\n",
      "0.0078:loss  ----- Training EPOCH 85 --- theta: tensor([0.4249, 0.2232, 0.5600, 0.2326, 0.5347], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006528232479467988\n",
      "Adjusting learning rate of group 0 to 2.9876e-04.\n",
      "0.0078:loss  ----- Training EPOCH 86 --- theta: tensor([0.4246, 0.2232, 0.5600, 0.2325, 0.5346], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006528245867229998\n",
      "Adjusting learning rate of group 0 to 2.8681e-04.\n",
      "0.0078:loss  ----- Training EPOCH 87 --- theta: tensor([0.4243, 0.2233, 0.5599, 0.2324, 0.5346], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006529100937768817\n",
      "Adjusting learning rate of group 0 to 2.7534e-04.\n",
      "0.0078:loss  ----- Training EPOCH 88 --- theta: tensor([0.4240, 0.2233, 0.5599, 0.2324, 0.5346], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006530819227918983\n",
      "Adjusting learning rate of group 0 to 2.6433e-04.\n",
      "0.0077:loss  ----- Training EPOCH 89 --- theta: tensor([0.4238, 0.2233, 0.5599, 0.2323, 0.5346], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006533427513204515\n",
      "Adjusting learning rate of group 0 to 2.5375e-04.\n",
      "0.0077:loss  ----- Training EPOCH 90 --- theta: tensor([0.4235, 0.2234, 0.5598, 0.2323, 0.5346], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006537183071486652\n",
      "Adjusting learning rate of group 0 to 2.4360e-04.\n",
      "0.0077:loss  ----- Training EPOCH 91 --- theta: tensor([0.4233, 0.2234, 0.5598, 0.2322, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006541160400956869\n",
      "Adjusting learning rate of group 0 to 2.3386e-04.\n",
      "0.0077:loss  ----- Training EPOCH 92 --- theta: tensor([0.4230, 0.2234, 0.5597, 0.2322, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006545909564010799\n",
      "Adjusting learning rate of group 0 to 2.2450e-04.\n",
      "0.0077:loss  ----- Training EPOCH 93 --- theta: tensor([0.4228, 0.2235, 0.5597, 0.2322, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006551235564984381\n",
      "Adjusting learning rate of group 0 to 2.1552e-04.\n",
      "0.0077:loss  ----- Training EPOCH 94 --- theta: tensor([0.4226, 0.2235, 0.5597, 0.2321, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006556991138495505\n",
      "Adjusting learning rate of group 0 to 2.0690e-04.\n",
      "0.0077:loss  ----- Training EPOCH 95 --- theta: tensor([0.4223, 0.2235, 0.5596, 0.2321, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006563141942024231\n",
      "Adjusting learning rate of group 0 to 1.9863e-04.\n",
      "0.0077:loss  ----- Training EPOCH 96 --- theta: tensor([0.4221, 0.2235, 0.5596, 0.2321, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006569608231075108\n",
      "Adjusting learning rate of group 0 to 1.9068e-04.\n",
      "0.0076:loss  ----- Training EPOCH 97 --- theta: tensor([0.4219, 0.2236, 0.5595, 0.2321, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006576451123692095\n",
      "Adjusting learning rate of group 0 to 1.8305e-04.\n",
      "0.0076:loss  ----- Training EPOCH 98 --- theta: tensor([0.4218, 0.2236, 0.5595, 0.2320, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006583280628547072\n",
      "Adjusting learning rate of group 0 to 1.7573e-04.\n",
      "0.0076:loss  ----- Training EPOCH 99 --- theta: tensor([0.4216, 0.2236, 0.5595, 0.2320, 0.5345], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006590195698663592\n",
      "Adjusting learning rate of group 0 to 1.6870e-04.\n",
      "0.0076:loss  ----- Training EPOCH 100 --- theta: tensor([0.4214, 0.2237, 0.5594, 0.2320, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006597403553314507\n",
      "Adjusting learning rate of group 0 to 1.6196e-04.\n",
      "0.0076:loss  ----- Training EPOCH 101 --- theta: tensor([0.4212, 0.2237, 0.5594, 0.2320, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006604514201171696\n",
      "Adjusting learning rate of group 0 to 1.5548e-04.\n",
      "0.0076:loss  ----- Training EPOCH 102 --- theta: tensor([0.4211, 0.2237, 0.5594, 0.2319, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006611642893403769\n",
      "Adjusting learning rate of group 0 to 1.4926e-04.\n",
      "0.0076:loss  ----- Training EPOCH 103 --- theta: tensor([0.4209, 0.2237, 0.5593, 0.2319, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000661873840726912\n",
      "Adjusting learning rate of group 0 to 1.4329e-04.\n",
      "0.0076:loss  ----- Training EPOCH 104 --- theta: tensor([0.4208, 0.2237, 0.5593, 0.2319, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006625943933613598\n",
      "Adjusting learning rate of group 0 to 1.3756e-04.\n",
      "0.0076:loss  ----- Training EPOCH 105 --- theta: tensor([0.4206, 0.2238, 0.5593, 0.2319, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006632905569858849\n",
      "Adjusting learning rate of group 0 to 1.3205e-04.\n",
      "0.0076:loss  ----- Training EPOCH 106 --- theta: tensor([0.4205, 0.2238, 0.5593, 0.2319, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006639990024268627\n",
      "Adjusting learning rate of group 0 to 1.2677e-04.\n",
      "0.0076:loss  ----- Training EPOCH 107 --- theta: tensor([0.4204, 0.2238, 0.5592, 0.2318, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006646845140494406\n",
      "Adjusting learning rate of group 0 to 1.2170e-04.\n",
      "0.0076:loss  ----- Training EPOCH 108 --- theta: tensor([0.4202, 0.2238, 0.5592, 0.2318, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000665369734633714\n",
      "Adjusting learning rate of group 0 to 1.1683e-04.\n",
      "0.0075:loss  ----- Training EPOCH 109 --- theta: tensor([0.4201, 0.2238, 0.5592, 0.2318, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006659977370873094\n",
      "Adjusting learning rate of group 0 to 1.1216e-04.\n",
      "0.0075:loss  ----- Training EPOCH 110 --- theta: tensor([0.4200, 0.2239, 0.5592, 0.2318, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006666573463007808\n",
      "Adjusting learning rate of group 0 to 1.0767e-04.\n",
      "0.0075:loss  ----- Training EPOCH 111 --- theta: tensor([0.4199, 0.2239, 0.5591, 0.2318, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006673032767139375\n",
      "Adjusting learning rate of group 0 to 1.0337e-04.\n",
      "0.0075:loss  ----- Training EPOCH 112 --- theta: tensor([0.4198, 0.2239, 0.5591, 0.2318, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006679241196252406\n",
      "Adjusting learning rate of group 0 to 9.9231e-05.\n",
      "0.0075:loss  ----- Training EPOCH 113 --- theta: tensor([0.4197, 0.2239, 0.5591, 0.2317, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006685391999781132\n",
      "Adjusting learning rate of group 0 to 9.5262e-05.\n",
      "0.0075:loss  ----- Training EPOCH 114 --- theta: tensor([0.4196, 0.2239, 0.5591, 0.2317, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006691290764138103\n",
      "Adjusting learning rate of group 0 to 9.1452e-05.\n",
      "0.0075:loss  ----- Training EPOCH 115 --- theta: tensor([0.4195, 0.2239, 0.5590, 0.2317, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006697085336782038\n",
      "Adjusting learning rate of group 0 to 8.7794e-05.\n",
      "0.0075:loss  ----- Training EPOCH 116 --- theta: tensor([0.4194, 0.2239, 0.5590, 0.2317, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006702917744405568\n",
      "Adjusting learning rate of group 0 to 8.4282e-05.\n",
      "0.0075:loss  ----- Training EPOCH 117 --- theta: tensor([0.4193, 0.2239, 0.5590, 0.2317, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006708301953040063\n",
      "Adjusting learning rate of group 0 to 8.0911e-05.\n",
      "0.0075:loss  ----- Training EPOCH 118 --- theta: tensor([0.4192, 0.2240, 0.5590, 0.2317, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006713675102218986\n",
      "Adjusting learning rate of group 0 to 7.7674e-05.\n",
      "0.0075:loss  ----- Training EPOCH 119 --- theta: tensor([0.4192, 0.2240, 0.5590, 0.2317, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006718955701217055\n",
      "Adjusting learning rate of group 0 to 7.4567e-05.\n",
      "0.0075:loss  ----- Training EPOCH 120 --- theta: tensor([0.4191, 0.2240, 0.5590, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006723756087012589\n",
      "Adjusting learning rate of group 0 to 7.1585e-05.\n",
      "0.0075:loss  ----- Training EPOCH 121 --- theta: tensor([0.4190, 0.2240, 0.5589, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006728640291839838\n",
      "Adjusting learning rate of group 0 to 6.8721e-05.\n",
      "0.0075:loss  ----- Training EPOCH 122 --- theta: tensor([0.4190, 0.2240, 0.5589, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006733561167493463\n",
      "Adjusting learning rate of group 0 to 6.5972e-05.\n",
      "0.0075:loss  ----- Training EPOCH 123 --- theta: tensor([0.4189, 0.2240, 0.5589, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006738225929439068\n",
      "Adjusting learning rate of group 0 to 6.3333e-05.\n",
      "0.0075:loss  ----- Training EPOCH 124 --- theta: tensor([0.4188, 0.2240, 0.5589, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006742557743564248\n",
      "Adjusting learning rate of group 0 to 6.0800e-05.\n",
      "0.0075:loss  ----- Training EPOCH 125 --- theta: tensor([0.4188, 0.2240, 0.5589, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006746986182406545\n",
      "Adjusting learning rate of group 0 to 5.8368e-05.\n",
      "0.0075:loss  ----- Training EPOCH 126 --- theta: tensor([0.4187, 0.2240, 0.5589, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006751044420525432\n",
      "Adjusting learning rate of group 0 to 5.6033e-05.\n",
      "0.0075:loss  ----- Training EPOCH 127 --- theta: tensor([0.4186, 0.2240, 0.5588, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000675523653626442\n",
      "Adjusting learning rate of group 0 to 5.3792e-05.\n",
      "0.0075:loss  ----- Training EPOCH 128 --- theta: tensor([0.4186, 0.2241, 0.5588, 0.2316, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006759236566722393\n",
      "Adjusting learning rate of group 0 to 5.1640e-05.\n",
      "0.0075:loss  ----- Training EPOCH 129 --- theta: tensor([0.4185, 0.2241, 0.5588, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006762979901395738\n",
      "Adjusting learning rate of group 0 to 4.9575e-05.\n",
      "0.0075:loss  ----- Training EPOCH 130 --- theta: tensor([0.4185, 0.2241, 0.5588, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006766755832359195\n",
      "Adjusting learning rate of group 0 to 4.7592e-05.\n",
      "0.0074:loss  ----- Training EPOCH 131 --- theta: tensor([0.4184, 0.2241, 0.5588, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000677040487062186\n",
      "Adjusting learning rate of group 0 to 4.5688e-05.\n",
      "0.0074:loss  ----- Training EPOCH 132 --- theta: tensor([0.4184, 0.2241, 0.5588, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000677379546687007\n",
      "Adjusting learning rate of group 0 to 4.3861e-05.\n",
      "0.0074:loss  ----- Training EPOCH 133 --- theta: tensor([0.4184, 0.2241, 0.5588, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006777237285859883\n",
      "Adjusting learning rate of group 0 to 4.2106e-05.\n",
      "0.0074:loss  ----- Training EPOCH 134 --- theta: tensor([0.4183, 0.2241, 0.5588, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006780372350476682\n",
      "Adjusting learning rate of group 0 to 4.0422e-05.\n",
      "0.0074:loss  ----- Training EPOCH 135 --- theta: tensor([0.4183, 0.2241, 0.5588, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006783687858842313\n",
      "Adjusting learning rate of group 0 to 3.8805e-05.\n",
      "0.0074:loss  ----- Training EPOCH 136 --- theta: tensor([0.4182, 0.2241, 0.5587, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000678658252581954\n",
      "Adjusting learning rate of group 0 to 3.7253e-05.\n",
      "0.0074:loss  ----- Training EPOCH 137 --- theta: tensor([0.4182, 0.2241, 0.5587, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006789657636545599\n",
      "Adjusting learning rate of group 0 to 3.5763e-05.\n",
      "0.0074:loss  ----- Training EPOCH 138 --- theta: tensor([0.4182, 0.2241, 0.5587, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006792457425035536\n",
      "Adjusting learning rate of group 0 to 3.4332e-05.\n",
      "0.0074:loss  ----- Training EPOCH 139 --- theta: tensor([0.4181, 0.2241, 0.5587, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006795192020945251\n",
      "Adjusting learning rate of group 0 to 3.2959e-05.\n",
      "0.0074:loss  ----- Training EPOCH 140 --- theta: tensor([0.4181, 0.2241, 0.5587, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006797881214879453\n",
      "Adjusting learning rate of group 0 to 3.1641e-05.\n",
      "0.0074:loss  ----- Training EPOCH 141 --- theta: tensor([0.4181, 0.2241, 0.5587, 0.2315, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006800619303248823\n",
      "Adjusting learning rate of group 0 to 3.0375e-05.\n",
      "0.0074:loss  ----- Training EPOCH 142 --- theta: tensor([0.4180, 0.2241, 0.5587, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006802920252084732\n",
      "Adjusting learning rate of group 0 to 2.9160e-05.\n",
      "0.0074:loss  ----- Training EPOCH 143 --- theta: tensor([0.4180, 0.2241, 0.5587, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006805399898439646\n",
      "Adjusting learning rate of group 0 to 2.7994e-05.\n",
      "0.0074:loss  ----- Training EPOCH 144 --- theta: tensor([0.4180, 0.2241, 0.5587, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006807719473727047\n",
      "Adjusting learning rate of group 0 to 2.6874e-05.\n",
      "0.0074:loss  ----- Training EPOCH 145 --- theta: tensor([0.4179, 0.2241, 0.5587, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006810069899074733\n",
      "Adjusting learning rate of group 0 to 2.5799e-05.\n",
      "0.0074:loss  ----- Training EPOCH 146 --- theta: tensor([0.4179, 0.2241, 0.5587, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006812179344706237\n",
      "Adjusting learning rate of group 0 to 2.4767e-05.\n",
      "0.0074:loss  ----- Training EPOCH 147 --- theta: tensor([0.4179, 0.2242, 0.5587, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006814433727413416\n",
      "Adjusting learning rate of group 0 to 2.3776e-05.\n",
      "0.0074:loss  ----- Training EPOCH 148 --- theta: tensor([0.4179, 0.2242, 0.5587, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006816594977863133\n",
      "Adjusting learning rate of group 0 to 2.2825e-05.\n",
      "0.0074:loss  ----- Training EPOCH 149 --- theta: tensor([0.4178, 0.2242, 0.5587, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006818347610533237\n",
      "Adjusting learning rate of group 0 to 2.1912e-05.\n",
      "0.0074:loss  ----- Training EPOCH 150 --- theta: tensor([0.4178, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006820298731327057\n",
      "Adjusting learning rate of group 0 to 2.1036e-05.\n",
      "0.0074:loss  ----- Training EPOCH 151 --- theta: tensor([0.4178, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006822005962021649\n",
      "Adjusting learning rate of group 0 to 2.0194e-05.\n",
      "0.0074:loss  ----- Training EPOCH 152 --- theta: tensor([0.4178, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006823680596426129\n",
      "Adjusting learning rate of group 0 to 1.9386e-05.\n",
      "0.0074:loss  ----- Training EPOCH 153 --- theta: tensor([0.4178, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006825565942563117\n",
      "Adjusting learning rate of group 0 to 1.8611e-05.\n",
      "0.0074:loss  ----- Training EPOCH 154 --- theta: tensor([0.4177, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006827111938036978\n",
      "Adjusting learning rate of group 0 to 1.7867e-05.\n",
      "0.0074:loss  ----- Training EPOCH 155 --- theta: tensor([0.4177, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000682873884215951\n",
      "Adjusting learning rate of group 0 to 1.7152e-05.\n",
      "0.0074:loss  ----- Training EPOCH 156 --- theta: tensor([0.4177, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006830301717855036\n",
      "Adjusting learning rate of group 0 to 1.6466e-05.\n",
      "0.0074:loss  ----- Training EPOCH 157 --- theta: tensor([0.4177, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006831767386756837\n",
      "Adjusting learning rate of group 0 to 1.5807e-05.\n",
      "0.0074:loss  ----- Training EPOCH 158 --- theta: tensor([0.4177, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000683326565194875\n",
      "Adjusting learning rate of group 0 to 1.5175e-05.\n",
      "0.0074:loss  ----- Training EPOCH 159 --- theta: tensor([0.4177, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006834844243712723\n",
      "Adjusting learning rate of group 0 to 1.4568e-05.\n",
      "0.0074:loss  ----- Training EPOCH 160 --- theta: tensor([0.4176, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000683605030644685\n",
      "Adjusting learning rate of group 0 to 1.3985e-05.\n",
      "0.0074:loss  ----- Training EPOCH 161 --- theta: tensor([0.4176, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006837340770289302\n",
      "Adjusting learning rate of group 0 to 1.3426e-05.\n",
      "0.0074:loss  ----- Training EPOCH 162 --- theta: tensor([0.4176, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006838433910161257\n",
      "Adjusting learning rate of group 0 to 1.2889e-05.\n",
      "0.0074:loss  ----- Training EPOCH 163 --- theta: tensor([0.4176, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006839563138782978\n",
      "Adjusting learning rate of group 0 to 1.2373e-05.\n",
      "0.0074:loss  ----- Training EPOCH 164 --- theta: tensor([0.4176, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006840657442808151\n",
      "Adjusting learning rate of group 0 to 1.1878e-05.\n",
      "0.0074:loss  ----- Training EPOCH 165 --- theta: tensor([0.4176, 0.2242, 0.5586, 0.2314, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006841898430138826\n",
      "Adjusting learning rate of group 0 to 1.1403e-05.\n",
      "0.0074:loss  ----- Training EPOCH 166 --- theta: tensor([0.4176, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006843027076683939\n",
      "Adjusting learning rate of group 0 to 1.0947e-05.\n",
      "0.0074:loss  ----- Training EPOCH 167 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006844072486273944\n",
      "Adjusting learning rate of group 0 to 1.0509e-05.\n",
      "0.0074:loss  ----- Training EPOCH 168 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006845120224170387\n",
      "Adjusting learning rate of group 0 to 1.0089e-05.\n",
      "0.0074:loss  ----- Training EPOCH 169 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006845843745395541\n",
      "Adjusting learning rate of group 0 to 9.6852e-06.\n",
      "0.0074:loss  ----- Training EPOCH 170 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006846890901215374\n",
      "Adjusting learning rate of group 0 to 9.2978e-06.\n",
      "0.0074:loss  ----- Training EPOCH 171 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006847695331089199\n",
      "Adjusting learning rate of group 0 to 8.9259e-06.\n",
      "0.0074:loss  ----- Training EPOCH 172 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006848582997918129\n",
      "Adjusting learning rate of group 0 to 8.5689e-06.\n",
      "0.0074:loss  ----- Training EPOCH 173 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006849369965493679\n",
      "Adjusting learning rate of group 0 to 8.2261e-06.\n",
      "0.0074:loss  ----- Training EPOCH 174 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006850272184237838\n",
      "Adjusting learning rate of group 0 to 7.8971e-06.\n",
      "0.0074:loss  ----- Training EPOCH 175 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006851109792478383\n",
      "Adjusting learning rate of group 0 to 7.5812e-06.\n",
      "0.0074:loss  ----- Training EPOCH 176 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006851818761788309\n",
      "Adjusting learning rate of group 0 to 7.2779e-06.\n",
      "0.0074:loss  ----- Training EPOCH 177 --- theta: tensor([0.4175, 0.2242, 0.5586, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006852559163235128\n",
      "Adjusting learning rate of group 0 to 6.9868e-06.\n",
      "0.0074:loss  ----- Training EPOCH 178 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006853041704744101\n",
      "Adjusting learning rate of group 0 to 6.7073e-06.\n",
      "0.0074:loss  ----- Training EPOCH 179 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006853879312984645\n",
      "Adjusting learning rate of group 0 to 6.4391e-06.\n",
      "0.0074:loss  ----- Training EPOCH 180 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006854459061287344\n",
      "Adjusting learning rate of group 0 to 6.1815e-06.\n",
      "0.0074:loss  ----- Training EPOCH 181 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006855117972008884\n",
      "Adjusting learning rate of group 0 to 5.9342e-06.\n",
      "0.0074:loss  ----- Training EPOCH 182 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006855794345028698\n",
      "Adjusting learning rate of group 0 to 5.6969e-06.\n",
      "0.0074:loss  ----- Training EPOCH 183 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006856292602606118\n",
      "Adjusting learning rate of group 0 to 5.4690e-06.\n",
      "0.0074:loss  ----- Training EPOCH 184 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006856822874397039\n",
      "Adjusting learning rate of group 0 to 5.2502e-06.\n",
      "0.0074:loss  ----- Training EPOCH 185 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006857370608486235\n",
      "Adjusting learning rate of group 0 to 5.0402e-06.\n",
      "0.0074:loss  ----- Training EPOCH 186 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006857806001789868\n",
      "Adjusting learning rate of group 0 to 4.8386e-06.\n",
      "0.0074:loss  ----- Training EPOCH 187 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000685833627358079\n",
      "Adjusting learning rate of group 0 to 4.6451e-06.\n",
      "0.0074:loss  ----- Training EPOCH 188 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006858882843516767\n",
      "Adjusting learning rate of group 0 to 4.4593e-06.\n",
      "0.0074:loss  ----- Training EPOCH 189 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000685923732817173\n",
      "Adjusting learning rate of group 0 to 4.2809e-06.\n",
      "0.0074:loss  ----- Training EPOCH 190 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.000685981591232121\n",
      "Adjusting learning rate of group 0 to 4.1097e-06.\n",
      "0.0074:loss  ----- Training EPOCH 191 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006860234425403178\n",
      "Adjusting learning rate of group 0 to 3.9453e-06.\n",
      "0.0074:loss  ----- Training EPOCH 192 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006860458524897695\n",
      "Adjusting learning rate of group 0 to 3.7875e-06.\n",
      "0.0074:loss  ----- Training EPOCH 193 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006860829307697713\n",
      "Adjusting learning rate of group 0 to 3.6360e-06.\n",
      "0.0074:loss  ----- Training EPOCH 194 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006861328729428351\n",
      "Adjusting learning rate of group 0 to 3.4905e-06.\n",
      "0.0074:loss  ----- Training EPOCH 195 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006861682049930096\n",
      "Adjusting learning rate of group 0 to 3.3509e-06.\n",
      "0.0074:loss  ----- Training EPOCH 196 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006861971342004836\n",
      "Adjusting learning rate of group 0 to 3.2169e-06.\n",
      "0.0074:loss  ----- Training EPOCH 197 --- theta: tensor([0.4174, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006862293230369687\n",
      "Adjusting learning rate of group 0 to 3.0882e-06.\n",
      "0.0074:loss  ----- Training EPOCH 198 --- theta: tensor([0.4173, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006862597074359655\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "0.0074:loss  ----- Training EPOCH 199 --- theta: tensor([0.4173, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n",
      "Num non-zero gadients: 1, incices: 4, gradients: 0.0006862871232442558\n",
      "Adjusting learning rate of group 0 to 2.8461e-06.\n",
      "tensor([0.2349, 0.2402, 0.2022, 0.2169, 0.2294], requires_grad=True)\n",
      "tensor([0.4173, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bucket_nn.set_value(PRECIP_RECORD, torch.tensor(network_precip_input_list, requires_grad=False))\n",
    "y_pred, loss = train_ncnn(bucket_nn, network_precip_tensor, network_outflow_tensor_0)\n",
    "network_outflow_list_1b = list(y_pred.detach().numpy())\n",
    "print(bucket_net.theta)\n",
    "print(bucket_nn.theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354211ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb89e7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x333.333 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startplt = 230\n",
    "endplt = 280\n",
    "bigfontsize = 12\n",
    "smallfontsize = 10\n",
    "# Set figure size to 7 inches wide\n",
    "figure_width = 5  # inches\n",
    "aspect_ratio = 3 / 2  # Adjust as needed for your plot\n",
    "figure_height = figure_width / aspect_ratio\n",
    "\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Set color\n",
    "light_blue_color = \"#3D68CA\"\n",
    "line_and_text_color = \"#0D3F6E\"\n",
    "\n",
    "# Plot each series with specified color\n",
    "plt.plot(network_precip_input_list[startplt:endplt], c=light_blue_color, lw=3, label=\"Precipitation input\")\n",
    "plt.plot(network_outflow_list_0[startplt:endplt], c=\"k\", lw=3, label=\"Target hydrograph \")\n",
    "plt.plot(network_outflow_list_1a[startplt:endplt], \"--\", lw=2, c=line_and_text_color, label=\"Pre-trained network\")\n",
    "plt.plot(network_outflow_list_1b[startplt:endplt], lw=3, c=\"r\", label=\"Trained bucket network\")\n",
    "\n",
    "network_precip_tensor = torch.tensor(network_precip_input_list)\n",
    "max_value = torch.max(network_precip_tensor[startplt:endplt]).item()\n",
    "#    plt.ylim([0, max_value * 1.2])\n",
    "\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Unit hydrograph\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "plt.xlabel(\"Time\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "\n",
    "# Modify legend to have a transparent background\n",
    "plt.legend(fontsize=smallfontsize, edgecolor=line_and_text_color, framealpha=0.5)  # Adjust framealpha as needed\n",
    "\n",
    "#    plt.title(\"Flow out from network and precip\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "\n",
    "# Save the figure with transparent background and at 300 DPI\n",
    "plt.show()\n",
    "#plt.savefig(\"ncn_plot.png\", transparent=True, dpi=300)\n",
    "\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd9eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d717beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'H': tensor([17.0996], grad_fn=<ViewBackward0>),\n",
       "  'S': tensor([[[0.4963, 0.7682],\n",
       "           [0.0885, 0.1320]]]),\n",
       "  's_q': tensor([[2.9423, 0.0558]], grad_fn=<SliceBackward0>)},\n",
       " 1: {'H': tensor([6.9922, 1.7508], grad_fn=<ViewBackward0>),\n",
       "  'S': tensor([[[0.3074, 0.6341]],\n",
       "  \n",
       "          [[0.4901, 0.8964]]]),\n",
       "  's_q': tensor([[0.8833],\n",
       "          [0.3309]], grad_fn=<SliceBackward0>)},\n",
       " 2: {'H': tensor([1.8070], grad_fn=<ViewBackward0>),\n",
       "  'S': tensor([[[0.4556, 0.6323]]]),\n",
       "  's_q': tensor([[0.3097]], grad_fn=<SliceBackward0>)}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_net.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91cb5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'H': tensor([17.5017], grad_fn=<ViewBackward0>),\n",
       "  'S': tensor([[[0.7576, 0.2793],\n",
       "           [0.4031, 0.7347]]]),\n",
       "  's_q': tensor([[0.0887, 2.7154]], grad_fn=<SliceBackward0>)},\n",
       " 1: {'H': tensor([6.8114, 1.8634], grad_fn=<ViewBackward0>),\n",
       "  'S': tensor([[[0.0293, 0.7999]],\n",
       "  \n",
       "          [[0.3971, 0.7544]]]),\n",
       "  's_q': tensor([[0.7188],\n",
       "          [0.3568]], grad_fn=<SliceBackward0>)},\n",
       " 2: {'H': tensor([15.9509], grad_fn=<ViewBackward0>),\n",
       "  'S': tensor([[[0.5695, 0.4388]]]),\n",
       "  's_q': tensor([[0.2975]], grad_fn=<SliceBackward0>)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_nn.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568b565c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2349, 0.2402, 0.2022, 0.2169, 0.2294], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_net.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3befa50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4173, 0.2242, 0.5585, 0.2313, 0.5344], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_nn.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d204aa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4921, 0.3090, 0.4843, 0.3580, 0.6444])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origional_bucket_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888d8141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3220, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(bucket_nn.theta - origional_bucket_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "553672bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0748, -0.0848,  0.0742, -0.1267, -0.1099], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_nn.theta - origional_bucket_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4455c9a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thislinewillstopthenotebookfromrunningthecellsbelow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mthislinewillstopthenotebookfromrunningthecellsbelow\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'thislinewillstopthenotebookfromrunningthecellsbelow' is not defined"
     ]
    }
   ],
   "source": [
    "print(thislinewillstopthenotebookfromrunningthecellsbelow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a7c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_TIMESTEPS):\n",
    "\n",
    "    ###########################################################################\n",
    "    ###########################################################################\n",
    "    bucket_nn.set_value(PRECIP_SVN, torch.tensor(network_precip_input_list[i], requires_grad=True))\n",
    "    if bucket_nn.do_predict_theta_with_lstm:\n",
    "        sequence_tensors = []\n",
    "        tensor_device = bucket_nn.network[0]['H'].device\n",
    "        tensor_dtype = torch.float32\n",
    "        if i >= bucket_nn.input_u_sequence_length:\n",
    "            sequence_tensors = [torch.tensor([item], device=tensor_device, dtype=tensor_dtype) \n",
    "                                for item in network_precip_input_list[i-bucket_nn.input_u_sequence_length:i]]\n",
    "        else:\n",
    "            desired_tensor_shape = (1,)\n",
    "            padding_size = bucket_nn.input_u_sequence_length - i\n",
    "            padding_tensors = [torch.zeros(desired_tensor_shape, device=tensor_device, dtype=tensor_dtype) \n",
    "                            for _ in range(padding_size)]\n",
    "            sequence_tensors = padding_tensors + [torch.tensor([item], device=tensor_device, dtype=tensor_dtype) \n",
    "                                                for item in network_precip_input_list[:i]]\n",
    "        sequence = torch.stack(sequence_tensors).view(1, -1)\n",
    "        bucket_nn.set_value(PRECIP_SVN_SEQ, sequence)\n",
    "\n",
    "\n",
    "    bucket_nn.update()\n",
    "    network_outflow_list_1b.append(bucket_nn.network_outflow.item())\n",
    "    bucket_nn.summarize_network()\n",
    "\n",
    "    if i in [180, 200]:\n",
    "        print(bucket_nn.theta)\n",
    "        print(bucket_nn.get_the_H_tensor())\n",
    "    ###########################################################################\n",
    "    ###########################################################################\n",
    "\n",
    "    if DO_PLOT:\n",
    "        if i % int(N_TIMESTEPS/10) == 0:\n",
    "            plt.plot([tensor.item() for tensor in bucket_nn.mean_H_per_layer])\n",
    "\n",
    "###########################################################################\n",
    "network_outflow_tensor_1 = torch.tensor(network_outflow_list_1b, requires_grad=True)\n",
    "bucket_nn.report_out_mass_balance()\n",
    "\n",
    "origional_bucket_theta = copy.deepcopy(bucket_nn.theta.detach())\n",
    "\n",
    "if DO_PLOT:\n",
    "    plt.title(\"Mean head in each bucket per layer\")\n",
    "    plt.ylabel(\"Average head per layer\")\n",
    "    plt.xlabel(\"Network Layers\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "if DO_PLOT:\n",
    "    startplt = 0\n",
    "    endplt = 250\n",
    "\n",
    "    plt.plot(network_precip_input_list, c=\"grey\", lw=0.5, label=\"Precipitation input\")\n",
    "    plt.plot(network_outflow_list_1b, label=\"Flow out of network\")\n",
    "    plt.xlim([startplt, endplt])\n",
    "    plt.ylim([0, torch.max(torch.tensor(network_precip_input_list)[startplt:endplt]).item()])\n",
    "    plt.legend()\n",
    "    plt.title(\"Warmup period\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    startplt = int(len(network_outflow_list_1b)-(len(network_outflow_list_1b)/2))\n",
    "    endplt = int(len(network_outflow_list_1b))\n",
    "    plt.plot(network_precip_input_list, c=\"grey\", lw=0.5, label=\"Precipitation input\")\n",
    "    plt.plot(network_outflow_list_1b, label=\"Flow out of network\")\n",
    "    plt.xlim([startplt, endplt])\n",
    "    plt.legend()\n",
    "    plt.title(\"Flow out from network and precip\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a76eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(thiscellwillstopthenotebookbeforethepureneuralnetworksaretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e37cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import Variable \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using CUDA device: \", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert arrays to PyTorch tensors\n",
    "x_input = torch.FloatTensor(network_precip_tensor.detach().numpy())\n",
    "y_target = torch.FloatTensor(network_outflow_tensor_0.detach().numpy())\n",
    "\n",
    "# Define the sequence length (you can adjust this)\n",
    "seq_length = 12\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(input_data, target_data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(input_data)-seq_length):\n",
    "        x_seq = input_data[i:i+seq_length]\n",
    "        y_seq = target_data[i+seq_length]\n",
    "        xs.append(x_seq)\n",
    "        ys.append(y_seq)\n",
    "    return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "X, y = create_sequences(x_input, y_target, seq_length)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=256, output_size=1, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=num_layers)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "\n",
    "model = LSTMModel()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    for seq, labels in zip(X, y):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(seq)\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch: {epoch} loss: {single_loss.item()}')\n",
    "\n",
    "print(f'Final loss: {single_loss.item()}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for seq in X:\n",
    "        predictions.append(model(seq).item())\n",
    "\n",
    "# Convert predictions to a numpy array for easy plotting\n",
    "predictions_np = np.array(predictions)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"LSTM Predictions vs Actual Data\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.plot(x_input.numpy()[seq_length:], label='Precipitation', alpha=0.7)\n",
    "plt.plot(y_target.numpy()[seq_length:], label='Actual Outflow', alpha=0.7)\n",
    "plt.plot(predictions_np, label='Predicted Outflow', alpha=0.7, linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert arrays to PyTorch tensors\n",
    "x_input = torch.FloatTensor(network_precip_tensor.detach().numpy())\n",
    "y_target = torch.FloatTensor(network_outflow_tensor_0.detach().numpy())\n",
    "\n",
    "# Define the sequence length (you can adjust this)\n",
    "seq_length = 35\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(input_data, target_data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(input_data) - seq_length):\n",
    "        x_seq = input_data[i:i + seq_length]\n",
    "        y_seq = target_data[i + seq_length]\n",
    "        xs.append(x_seq)\n",
    "        ys.append(y_seq)\n",
    "    return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "X, y = create_sequences(x_input, y_target, seq_length)\n",
    "\n",
    "# Feedforward Neural Network Model\n",
    "class FFNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size=3, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        # Define your feedforward layers here\n",
    "        self.fc1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.fc4 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        self.activations = []\n",
    "        x = self.fc1(input_seq)\n",
    "        self.activations.append(x.detach().numpy())  # Record activation\n",
    "        x = self.relu1(x)\n",
    "        self.activations.append(x.detach().numpy())  # Record activation\n",
    "        x = self.fc2(x)\n",
    "        self.activations.append(x.detach().numpy())  # Record activation\n",
    "        x = self.relu2(x)\n",
    "        self.activations.append(x.detach().numpy())  # Record activation\n",
    "        x = self.fc3(x)\n",
    "        self.activations.append(x.detach().numpy())  # Record activation\n",
    "        predictions = self.fc4(x)\n",
    "        return predictions[-1]\n",
    "\n",
    "model = FFNNModel(input_size=seq_length)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.006)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.99, verbose=True)\n",
    "\n",
    "epochs = 150\n",
    "for epoch in range(epochs):\n",
    "    for seq, labels in zip(X, y):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(seq)\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch: {epoch} loss: {single_loss.item():.4f}')\n",
    "\n",
    "print(f'Final loss: {single_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d416ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input.shape, y_target.shape, predictions_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, seq in enumerate(X):\n",
    "        predictions.append(model(seq).item())\n",
    "predictions_np = np.array(predictions)\n",
    "\n",
    "DO_PLOT = True\n",
    "if DO_PLOT:\n",
    "    startplt = 230\n",
    "    endplt = 280\n",
    "    bigfontsize = 22\n",
    "    smallfontsize = 16\n",
    "    # Set figure size to 7 inches wide\n",
    "    figure_width = 7  # inches\n",
    "    aspect_ratio = 3 / 2  # Adjust as needed for your plot\n",
    "    figure_height = figure_width / aspect_ratio\n",
    "\n",
    "    plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "    # Set color\n",
    "    light_blue_color = \"#3D68CA\"\n",
    "    line_and_text_color = \"#0D3F6E\"\n",
    "\n",
    "    # Plot each series with specified color\n",
    "    plt.plot(network_precip_input_list[startplt:endplt], c=light_blue_color, lw=10, label=\"Precipitation input\")\n",
    "    plt.plot(network_outflow_list_0[startplt:endplt], c=\"k\", lw=10, label=\"Target hydrograph \")\n",
    "    # plt.plot(network_outflow_list_1a[startplt:endplt], \"--\", lw=5, c=line_and_text_color, label=\"Pre-trained network\")\n",
    "    plt.plot(predictions_np[startplt-seq_length:endplt-seq_length], \"--\", lw=10, c=line_and_text_color, label=\"Trained bucket network\")\n",
    "\n",
    "    network_precip_tensor = torch.tensor(network_precip_input_list)\n",
    "    max_value = torch.max(network_precip_tensor[startplt:endplt]).item()\n",
    "    plt.ylim([0, max_value * 1.2])\n",
    "\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.ylabel(\"Unit hydrograph\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "    plt.xlabel(\"Time\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "\n",
    "    # Modify legend to have a transparent background\n",
    "    #plt.legend(fontsize=smallfontsize, edgecolor=line_and_text_color, framealpha=0.5)  # Adjust framealpha as needed\n",
    "\n",
    "    #plt.title(\"Flow out from network and precip\", fontsize=bigfontsize, color=line_and_text_color)\n",
    "\n",
    "    # Save the figure with transparent background and at 300 DPI\n",
    "    #plt.show()\n",
    "    plt.savefig(\"./figs/ffn_plot.png\", transparent=True, dpi=300)\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_the_time_series(x_input, y_target, predictions_np, seq_length):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(\"FFNN Predictions vs Actual Data\")\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Output\")\n",
    "    plt.plot(x_input.numpy()[seq_length:], label='Precipitation', alpha=0.7)\n",
    "    plt.plot(y_target.numpy()[seq_length:], label='Actual Outflow', alpha=0.7)\n",
    "    plt.plot(predictions_np, label='Predicted Outflow', alpha=0.7, linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, seq in enumerate(X):\n",
    "        predictions.append(model(seq).item())\n",
    "predictions_np = np.array(predictions)\n",
    "plot_the_time_series(x_input, y_target, predictions_np, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac67c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4548040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(thiscellwillstopthenotebookbeforetheanimationismade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_layer_connections_with_annotations(model, input_seq, title):\n",
    "    model(input_seq)  # Forward pass to record activations\n",
    "    activations = model.activations\n",
    "\n",
    "    # Concatenate activations horizontally\n",
    "    concatenated_activations = np.hstack([activation.reshape(-1, 1) for activation in activations])\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(3, 2))  # Adjust the figure size as needed\n",
    "    ax = sns.heatmap(concatenated_activations, annot=True, fmt=\".2f\", cmap=\"viridis\", annot_kws={\"size\": 8})\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Layer Neurons\")\n",
    "    plt.ylabel(\"Activation\")\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "for i in [50, 75]:\n",
    "    visualize_layer_connections_with_annotations(model, X[i], f\"Neuron Connections at x={i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57851cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5503f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891b699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_visualization_subplot(model, input_seq, layer_sizes, title, ax):\n",
    "    model(input_seq)  # Forward pass to record activations\n",
    "    activations = model.activations\n",
    "\n",
    "    # Create a color map\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "\n",
    "    # Normalize the activation values to [-5, 5] for the color map\n",
    "    norm = mcolors.Normalize(vmin=-5, vmax=5)\n",
    "\n",
    "    # Number of layers including input and output\n",
    "    num_layers = len(layer_sizes)\n",
    "\n",
    "    # List to store node positions, to be used to draw the edges\n",
    "    node_positions = {}\n",
    "\n",
    "    # Generate positions for each layer\n",
    "    for i, size in enumerate(layer_sizes):\n",
    "        # Vertical positions\n",
    "        v_positions = np.linspace(0, 1, size + 2)[1:-1]\n",
    "\n",
    "        # Horizontal position\n",
    "        h_position = i / (num_layers - 1)\n",
    "\n",
    "        # Draw nodes\n",
    "        for j, v in enumerate(v_positions):\n",
    "            activation = 0\n",
    "            if i > 0:  # Skip input layer for activations\n",
    "                activation = activations[i-1][j]\n",
    "            color = cmap(norm(activation))\n",
    "\n",
    "            circle = plt.Circle((h_position, v), 0.05, color=color, zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "            node_positions[(i, j)] = (h_position, v)\n",
    "\n",
    "            # Optionally, add activation values as text inside the nodes\n",
    "            # plt.text(h_position, v, f'{activation:.2f}', ha='center', va='center', color='white', fontsize=8)\n",
    "\n",
    "    # Draw edges\n",
    "    for i in range(num_layers - 1):\n",
    "        for j in range(layer_sizes[i]):\n",
    "            for k in range(layer_sizes[i + 1]):\n",
    "                start_pos = node_positions[(i, j)]\n",
    "                end_pos = node_positions[(i + 1, k)]\n",
    "                line = plt.Line2D([start_pos[0], end_pos[0]], [start_pos[1], end_pos[1]], c='black', alpha=0.3)\n",
    "                ax.add_line(line)\n",
    "\n",
    "    mappable = ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "    # Add a colorbar\n",
    "    plt.colorbar(mappable, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Set title and turn off axis\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9741cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_the_time_series_subplot(x_input, y_target, predictions_np, seq_length, t, ax):\n",
    "    ax.set_title(\"FFNN Predictions vs Actual Data\")\n",
    "    ax.set_xlabel(\"Time Steps\")\n",
    "    ax.set_ylabel(\"Output\")\n",
    "    ax.plot(x_input.numpy()[seq_length:], label='Precipitation', alpha=0.7)\n",
    "    ax.plot(y_target.numpy()[seq_length:], label='Actual Outflow', alpha=0.7)\n",
    "    ax.plot(predictions_np, label='Predicted Outflow', alpha=0.7, linestyle='--')\n",
    "    ax.axvline(x=t, color='red', linestyle='--')  # Vertical line\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bda8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of each layer (including input and output layers)\n",
    "layer_sizes = [1, 3, 3, 3, 1]  # Example: input layer with 35 nodes, three hidden layers with 3 nodes each, and an output layer with 1 node\n",
    "\n",
    "# Usage\n",
    "for t in range(1,200):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "    # Network visualization on the first subplot\n",
    "    network_visualization_subplot(model, X[t], layer_sizes, f\"Neural Network Visualization at t={t}\", ax1)\n",
    "\n",
    "    # Time series plot on the second subplot\n",
    "    plot_the_time_series_subplot(x_input, y_target, predictions_np, seq_length, t, ax2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./figs/network_plot/combined_frame_{t}.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64095e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f\"./figs/network_plot/combined_frame_{t}.png\" for t in range(1, 200)]\n",
    "images = [imageio.imread(filename) for filename in filenames]\n",
    "imageio.mimsave('network_animation.gif', images, fps=2)  # Adjust fps as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e6a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382c53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
